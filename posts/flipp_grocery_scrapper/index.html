<!DOCTYPE html><html lang="en"> <head><meta name="astro-view-transitions-enabled" content="true"><meta name="astro-view-transitions-fallback" content="animate"><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Automated Data Extraction from Online Retail Flyers Using Python and Selenium - FriendlyUsers Tech Blog</title><meta name="description" content="This article explores the `flipp_flyer_parser` Python script, an advanced web scraping tool for extracting promotional data from retail websites like Save-On-Foods, Walmart, and Superstore."><meta name="author" content="David Li"><link rel="alternate" type="application/rss+xml" href="/rss.xml"><link rel="icon" type="image/x-icon" href="/favicon.ico"><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2479144310234386" crossorigin="anonymous"></script><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-119155027-6"></script><script type="text/javascript">
      let slideIndex = 1;
      showSlides(slideIndex);

      function plusSlides(n) {
        showSlides((slideIndex += n));
      }

      function currentSlide(n) {
        showSlides((slideIndex = n));
      }

      function showSlides(n) {
        try {
          let i;
          let slides = document.getElementsByClassName('mySlides');
          let dots = document.getElementsByClassName('demo');
          let captionText = document.getElementById('caption');
          if (n > slides.length) {
            slideIndex = 1;
          }
          if (n < 1) {
            slideIndex = slides.length;
          }
          for (i = 0; i < slides.length; i++) {
            slides[i].style.display = 'none';
          }
          for (i = 0; i < dots.length; i++) {
            dots[i].className = dots[i].className.replace(' active', '');
          }
          slides[slideIndex - 1].style.display = 'block';
          dots[slideIndex - 1].className += ' active';
          captionText.innerHTML = dots[slideIndex - 1].alt;
        } catch (err) {
          // do nothing here
        }
      }
    </script><!-- Google Tag Manager --><!-- End Google Tag Manager --><link rel="stylesheet" href="/_astro/index.DFWZl3Z8.css" />
<style>.astro-route-announcer{position:absolute;left:0;top:0;clip:rect(0 0 0 0);-webkit-clip-path:inset(50%);clip-path:inset(50%);overflow:hidden;white-space:nowrap;width:1px;height:1px}@media print{.no-print,.no-print *{display:none!important}}
</style><script type="module" src="/_astro/hoisted.CcuKkQrI.js"></script></head> <body class="bg-slate-900 text-gray-100"> <!-- Google Tag Manager (noscript) --> <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-K8P5P8FQ" height="0" width="0" style="display:none;visibility:hidden"></iframe> </noscript> <!-- End Google Tag Manager (noscript) --> <div class="mx-auto max-w-screen-lg px-3 py-6"><div class="flex flex-col gap-y-3 sm:flex-row sm:items-center sm:justify-between"><a href="/"><div class="flex items-center bg-gradient-to-br from-sky-500 to-cyan-400 bg-clip-text text-xl font-bold text-transparent"><svg class="mr-1 h-10 w-10 stroke-cyan-600" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"><path d="M0 0h24v24H0z" stroke="none"></path><rect x="3" y="12" width="6" height="8" rx="1"></rect><rect x="9" y="8" width="6" height="12" rx="1"></rect><rect x="15" y="4" width="6" height="16" rx="1"></rect><path d="M4 20h14"></path></svg>David&#x27;s Blog</div></a><nav><ul class="flex gap-x-3 font-medium text-gray-200"><li class="hover:text-white"><a href="/posts">Blogs</a></li><li class="hover:text-white"><a href="https://github.com/FriendlyUser/astro-tech-blog">GitHub</a></li><li class="hover:text-white"><a href="/photos">Photos</a></li></ul></nav></div></div> <div data-pagefind-body>  <div class="mx-auto max-w-screen-lg px-3 py-6"><div><h1 class="text-center text-3xl font-bold">Automated Data Extraction from Online Retail Flyers Using Python and Selenium</h1><div class="mt-2 text-center text-sm text-gray-400">By <!-- -->David Li<!-- --> on <!-- -->Thursday, 15 Feburary 2023 13:00:00 GMT</div><div class="flex place-content-center pt-2"><div class="rounded-md px-2 py-1 text-xs font-semibold bg-green-400 text-green-900"> <a href="/tags/python" style="padding-right:3px"> <category>python<!-- --> </category></a></div> <div class="rounded-md px-2 py-1 text-xs font-semibold bg-cyan-400 text-cyan-900"> <a href="/tags/web scraping" style="padding-right:3px"> <category>web scraping<!-- --> </category></a></div> <div class="rounded-md px-2 py-1 text-xs font-semibold bg-cyan-400 text-cyan-900"> <a href="/tags/selenium" style="padding-right:3px"> <category>selenium<!-- --> </category></a></div> <div class="rounded-md px-2 py-1 text-xs font-semibold bg-cyan-400 text-cyan-900"> <a href="/tags/data extraction" style="padding-right:3px"> <category>data extraction<!-- --> </category></a></div> <div class="rounded-md px-2 py-1 text-xs font-semibold bg-cyan-400 text-cyan-900"> <a href="/tags/retail" style="padding-right:3px"> <category>retail<!-- --> </category></a></div> <div class="rounded-md px-2 py-1 text-xs font-semibold bg-cyan-400 text-cyan-900"> <a href="/tags/automation" style="padding-right:3px"> <category>automation<!-- --> </category></a></div> </div><div class="mx-auto mt-5 max-w-prose"><div class="aspect-w-3 aspect-h-2"><img class="h-full w-full rounded-lg object-cover object-center" src="/imgs/2023/117117315.png" alt="Python Web Scraping Visualization" loading="lazy"/></div><div class="prose prose-invert mt-8 prose-img:rounded-lg"><content> <h1 id="web-scraping-retail-flipp-flyers">Web Scraping Retail Flipp Flyers</h1>
<p>The <code>flipp_flyer_parser</code> Python script is a sophisticated web scraping tool, designed for extracting promotional flyer data from various retail websites. Authored by FriendlyUser, this script leverages Selenium, a powerful tool for browser automation, to navigate through web pages and extract relevant data. It focuses on three major Canadian retailers: Save-On-Foods, Walmart, and Superstore.</p>
<h2 id="key-components-and-libraries">Key Components and Libraries</h2>
<ul>
<li><strong>Selenium WebDriver (<code>undetected_chromedriver</code>)</strong>: Used for controlling a Chrome browser. This driver is essential for navigating through the web pages and interacting with web elements.</li>
<li><strong>Date Parsing (<code>dateutil.parser</code>)</strong>: Utilized for parsing date strings.</li>
<li><strong>Regular Expressions (<code>re</code>)</strong>: Employed for text pattern matching and data extraction from descriptions.</li>
<li><strong>Image Processing (<code>PIL</code>)</strong>: The Python Imaging Library (PIL) can be used for handling images, though its specific usage isn’t clear from the provided script.</li>
<li><strong>Argument Parsing (<code>argparse</code>)</strong>: Facilitates command-line argument parsing, allowing users to specify the store type.</li>
</ul>
<h2 id="core-functionalities">Core Functionalities</h2>
<h3 id="webdriver-setup">WebDriver Setup</h3>
<ul>
<li><code>make_driver()</code>: Creates a Chrome WebDriver instance with optional headless browsing.</li>
<li>Specific setup functions for each store (<code>selenium_setup_saveon</code>, <code>selenium_setup_walmart</code>, <code>setup_superstore</code>): These functions initialize the WebDriver and navigate to the respective store’s flyer page.</li>
</ul>
<h3 id="data-extraction">Data Extraction</h3>
<ul>
<li><code>parse_flipp_aside(driver, cfg)</code>: Extracts detailed information from a specific part of the webpage (flipp aside iframe). It retrieves various data like start and end dates, product descriptions, sizes, quantities, and more.</li>
<li><code>scrap_flyer(driver, cfg)</code>: Orchestrates the scraping process. It involves navigating through iframes, handling cookies, extracting HTML content, and iterating over flyer images to gather product data.</li>
</ul>
<h3 id="utility-functions">Utility Functions</h3>
<ul>
<li><code>swap_to_iframe(driver, iframe_class)</code>: Aids in switching between different iframes within a webpage.</li>
<li>StoreType <code>Enum</code>: Enumerates store types (SAVEON, WALMART, SUPERSTORE) for easier management.</li>
</ul>
<h3 id="main-function">Main Function</h3>
<ul>
<li>The script uses a command-line interface where the user can specify the store type.</li>
<li>Based on the store type, it calls the corresponding function to set up Selenium and scrape the flyer data.</li>
</ul>
<h2 id="technical-highlights">Technical Highlights</h2>
<h3 id="use-of-selenium">Use of Selenium</h3>
<ul>
<li>The script showcases an advanced use of Selenium for web scraping, handling dynamic content loaded through JavaScript and embedded iframes, which are common challenges in modern web scraping tasks.</li>
</ul>
<h3 id="regular-expressions">Regular Expressions</h3>
<ul>
<li>Extensive use of regex for parsing complex text patterns in product descriptions, which is crucial for accurate data extraction in web scraping projects.</li>
</ul>
<h3 id="error-handling">Error Handling</h3>
<ul>
<li>The script includes basic error handling, particularly in <code>parse_flipp_aside</code> and <code>scrap_flyer</code> functions, to manage exceptions like <code>NoSuchElementException</code>.</li>
</ul>
<h2 id="expanded-technical-analysis-of-flipp_flyer_parser">Expanded Technical Analysis of <code>flipp_flyer_parser</code></h2>
<p>We will delve into the more complex parts of the <code>flipp_flyer_parser</code> script, breaking down key functions and processes step by step.</p>
<h3 id="1-webdriver-setup">1. WebDriver Setup</h3>
<p>The script begins with setting up the Selenium WebDriver, crucial for browser automation.</p>
<h4 id="make_driver-function"><code>make_driver</code> Function</h4>
<ul>
<li>Initializes a Chrome WebDriver using <code>undetected_chromedriver</code>.</li>
<li>The function returns a WebDriver object with <code>headless=False</code> (meaning the browser UI is visible during scraping) and <code>use_subprocess=False</code>.</li>
</ul>
<h3 id="2-store-specific-setup-functions">2. Store-Specific Setup Functions</h3>
<p>These functions are tailored for each retail website, navigating to the respective flyer pages.</p>
<h4 id="selenium_setup_walmart-selenium_setup_saveon-and-setup_superstore-functions"><code>selenium_setup_walmart</code>, <code>selenium_setup_saveon</code>, and <code>setup_superstore</code> Functions</h4>
<ul>
<li>Each function creates a WebDriver instance via <code>make_driver()</code>.</li>
<li>Navigates to the specific URL of the store’s flyer page.</li>
<li>For <code>setup_superstore</code>, additional cookie manipulation is performed to mimic a user’s browser settings.</li>
</ul>
<h3 id="3-data-extraction">3. Data Extraction</h3>
<h4 id="parse_flipp_aside-function"><code>parse_flipp_aside</code> Function</h4>
<p>This function extracts detailed information from a part of the webpage, typically an iframe.</p>
<p><strong>Switching to the Relevant Iframe</strong>:</p>
<p>Calls <code>swap_to_iframe</code> with the class name of the iframe to be accessed.</p>
<p><strong>Extracting Information</strong>:</p>
<p>Finds elements by tag or class name (e.g., validity dates, descriptions).
Regular expressions are used to parse and extract data like sizes, quantities, and product types from the product description.
Exception handling is used to manage elements that might not be present.</p>
<h4 id="scrap_flyer-function"><code>scrap_flyer</code> Function</h4>
<p>This function orchestrates the overall scraping process.</p>
<p><strong>Initial Setup</strong>:</p>
<p>Waits for the main element of the page to become visible.
Handles exceptions by saving the page source to a file for debugging.</p>
<p><strong>Handling Cookies and HTML Content</strong>:
Retrieves and saves cookies to a JSON file.
Saves the HTML content of the page for further processing.</p>
<p><strong>Navigating Through Flyer Images</strong>:
Iterates over elements containing flyer images.
For each image, iterates over associated buttons that likely contain product information.
Executes a script to ensure the visibility of elements and interacts with them (clicking buttons).</p>
<p><strong>Extracting Product Data</strong>:
Each button’s label is parsed for product data.
Regular expressions are used to extract pricing information.
Calls <code>parse_flipp_aside</code> to extract additional details from the aside section.
Aggregates all extracted data into a dictionary and appends it to a list.</p>
<p><strong>Final Steps</strong>:
The data list is saved to a JSON file.
Handles a set maximum number of items to prevent excessive scraping.</p>
<h3 id="4-main-function">4. Main Function</h3>
<p>The script uses an argument parser to allow the user to specify the store type via the command line.</p>
<p>Based on the store type provided, the corresponding scraping function is called.
This modular approach allows for easy expansion or modification for different stores.</p>
<h3 id="conclusion">Conclusion</h3>
<p>The <code>flipp_flyer_parser</code> script is a comprehensive example of advanced web scraping using Python and Selenium. It demonstrates handling dynamic web content, navigating through complex webpage structures, and extracting structured data from unstructured HTML. The use of regular expressions and strategic error handling are notable for their efficiency in data parsing and resilience against web scraping challenges. This script serves as an excellent template for similar web scraping tasks, particularly those involving dynamic and interactive web content.</p> </content></div></div></div></div> <div class="mx-auto max-w-screen-lg px-3 py-6"> <div class="no-print flex w-full"> <form class="max-w-lg" action="https://formspree.io/f/davidli012345@gmail.com" method="POST"><div class="-mx-3 mb-6 flex flex-wrap"><div class="mb-6 w-full px-3 md:mb-0 md:w-1/2"><label class="mb-2 block text-xs font-bold uppercase tracking-wide" for="grid-first-name">First Name</label><input class="mb-3 block w-full appearance-none rounded py-3 px-4 leading-tight text-gray-700 focus:bg-white focus:outline-none" id="grid-first-name" type="text" placeholder="Jane"/></div><div class="w-full px-3 md:w-1/2"><label class="mb-2 block text-xs font-bold uppercase tracking-wide" for="grid-last-name">Last Name</label><input class="block w-full appearance-none rounded border border-gray-200  py-3 px-4 leading-tight text-gray-700 focus:border-gray-500 focus:bg-white focus:outline-none" id="grid-last-name" type="text" placeholder="Doe"/></div></div><div class="-mx-3 mb-6 flex flex-wrap"><div class="w-full px-3"><label class="mb-2 block text-xs font-bold uppercase tracking-wide" for="grid-password">E-mail</label><input class="mb-3 block w-full appearance-none rounded border py-3 px-4 leading-tight text-gray-700 focus:border-gray-500 focus:bg-white focus:outline-none" id="email" type="email"/></div></div><div class="-mx-3 mb-6 flex flex-wrap"><div class="w-full px-3"><label class="mb-2 block text-xs font-bold uppercase tracking-wide" for="grid-password">Message</label><textarea class="no-resize mb-3 block h-48 w-full resize-none appearance-none rounded border border-gray-200 py-3 px-4 leading-tight text-gray-700 focus:border-gray-500 focus:bg-white focus:outline-none" id="message"></textarea></div></div><div class="md:flex md:items-center"><div class="md:w-1/3"><button class="ml-2 shrink-0 rounded-full bg-gradient-to-br from-sky-500 to-cyan-400 px-3 py-1 text-sm font-medium text-gray-700 hover:from-sky-700 hover:to-cyan-600 focus:outline-none focus:ring-2 focus:ring-cyan-600/50" type="submit">Send</button></div><div class="md:w-2/3"></div></div></form> <div class="ml-3 max-w-lg bg-slate-300"> <link href="/_pagefind/pagefind-ui.css" rel="stylesheet"> <script src="/_pagefind/pagefind-ui.js" type="text/javascript"></script> <div id="search" class="ml-3 p-4"></div>  </div> </div> </div>  </div> <div class="mx-auto max-w-screen-lg px-3 py-6"><div class="no-print border-t border-gray-600 pt-5"><div class="text-sm text-gray-200">© Copyright <!-- -->2025<!-- --> by <!-- -->FriendlyUsers Tech Blog<!-- -->. Built with ♥ by<!-- --> <a class="text-cyan-400 hover:underline" href="https://github.com/FriendlyUser" target="_blank" rel="noopener noreferrer">FriendlyUser</a>. Last updated on <!-- -->2025-03-27<!-- -->.</div></div><script src="https://cdn.botpress.cloud/webchat/v0/inject.js"></script><script src="https://mediafiles.botpress.cloud/0df54034-3318-451a-aed0-3923a4ee25a5/webchat/config.js" defer=""></script></div> </body></html>